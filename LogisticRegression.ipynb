{ 
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist \n",
    "# the data, shuffled and split between train and test sets \n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784 #28*28 \n",
    "X_train = X_train.reshape(60000, input_dim) \n",
    "X_test = X_test.reshape(10000, input_dim) \n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32') \n",
    "X_train /= 255 \n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils \n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes) \n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "\r",
      "  128/60000 [..............................] - ETA: 38s - loss: 2.4517 - acc: 0.0547"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tigran/anaconda3/envs/p/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 13us/step - loss: 1.2771 - acc: 0.7107 - val_loss: 0.8108 - val_acc: 0.8355\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.7140 - acc: 0.8409 - val_loss: 0.6080 - val_acc: 0.8610\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5863 - acc: 0.8589 - val_loss: 0.5269 - val_acc: 0.8749\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.5250 - acc: 0.8694 - val_loss: 0.4811 - val_acc: 0.8812\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.4875 - acc: 0.8750 - val_loss: 0.4511 - val_acc: 0.8846\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.4618 - acc: 0.8796 - val_loss: 0.4297 - val_acc: 0.8882\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.4427 - acc: 0.8832 - val_loss: 0.4135 - val_acc: 0.8910\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.4277 - acc: 0.8860 - val_loss: 0.4009 - val_acc: 0.8941\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.4157 - acc: 0.8884 - val_loss: 0.3902 - val_acc: 0.8966\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.4057 - acc: 0.8902 - val_loss: 0.3817 - val_acc: 0.8980\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.3972 - acc: 0.8924 - val_loss: 0.3743 - val_acc: 0.8989\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.3900 - acc: 0.8935 - val_loss: 0.3680 - val_acc: 0.9008\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3836 - acc: 0.8956 - val_loss: 0.3622 - val_acc: 0.9023\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.3780 - acc: 0.8969 - val_loss: 0.3574 - val_acc: 0.9030\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.3730 - acc: 0.8979 - val_loss: 0.3529 - val_acc: 0.9038\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3684 - acc: 0.8989 - val_loss: 0.3490 - val_acc: 0.9048\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.3643 - acc: 0.8999 - val_loss: 0.3454 - val_acc: 0.9053\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3606 - acc: 0.9007 - val_loss: 0.3421 - val_acc: 0.9069\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3572 - acc: 0.9014 - val_loss: 0.3390 - val_acc: 0.9068\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3540 - acc: 0.9018 - val_loss: 0.3363 - val_acc: 0.9082\n",
      "Test score: 0.33629812779426577\n",
      "Test accuracy: 0.9082\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation \n",
    "output_dim = nb_classes = 10 \n",
    "model = Sequential() \n",
    "model.add(Dense(output_dim, input_dim=input_dim, activation='softmax')) \n",
    "batch_size = 128 \n",
    "nb_epoch = 20\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,verbose=1, validation_data=(X_test, Y_test)) \n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"class_name\": \"Sequential\", \"config\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"batch_input_shape\": [null, 784], \"dtype\": \"float32\", \"units\": 10, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}], \"keras_version\": \"2.2.2\", \"backend\": \"tensorflow\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "614"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string = model.to_json() # as json \n",
    "print(json_string)\n",
    "open('mnist_Logistic_model.json', 'w').write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "backend: tensorflow\n",
      "class_name: Sequential\n",
      "config:\n",
      "- class_name: Dense\n",
      "  config:\n",
      "    activation: softmax\n",
      "    activity_regularizer: null\n",
      "    batch_input_shape: !!python/tuple [null, 784]\n",
      "    bias_constraint: null\n",
      "    bias_initializer:\n",
      "      class_name: Zeros\n",
      "      config: {}\n",
      "    bias_regularizer: null\n",
      "    dtype: float32\n",
      "    kernel_constraint: null\n",
      "    kernel_initializer:\n",
      "      class_name: VarianceScaling\n",
      "      config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}\n",
      "    kernel_regularizer: null\n",
      "    name: dense_1\n",
      "    trainable: true\n",
      "    units: 10\n",
      "    use_bias: true\n",
      "keras_version: 2.2.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yaml_string = model.to_yaml() #as yaml \n",
    "print('-' * 20)\n",
    "print(yaml_string)\n",
    "# open('mnist_Logistic_model.yaml', 'w').write(yaml_string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "[<tf.Variable 'dense_1/kernel:0' shape=(784, 10) dtype=float32_ref>, <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "print('-' * 20)\n",
    "print(model.weights)\n",
    "# save the weights in h5 format \n",
    "model.save_weights('mnist_Logistic_wts.h5') \n",
    "# uncomment the code below (and modify accordingly) to read a saved model and weights \n",
    "# model = model_from_json(open('my_model_architecture.json').read())# if json \n",
    "# model = model_from_yaml(open('my_model_architecture.yaml').read())# if yaml \n",
    "# model.load_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ar = np.asarray(model.get_weights())\n",
    "print(ar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 10)\n",
      "(10,)\n",
      "[array([[ 0.01723874, -0.06937709,  0.06620833, ..., -0.0482297 ,\n",
      "        -0.01208302,  0.06472545],\n",
      "       [-0.0813828 ,  0.05895495,  0.07435621, ..., -0.01777029,\n",
      "        -0.02612485, -0.03271134],\n",
      "       [ 0.02603001,  0.01454788,  0.02440587, ..., -0.00488136,\n",
      "        -0.08620577, -0.04377325],\n",
      "       ...,\n",
      "       [ 0.05671767, -0.04640131,  0.05645337, ..., -0.02857556,\n",
      "         0.0272934 , -0.01572572],\n",
      "       [-0.01255121, -0.04810474,  0.02635325, ..., -0.06721019,\n",
      "        -0.06367881, -0.06284067],\n",
      "       [-0.07528649,  0.02209504, -0.01051965, ..., -0.05565882,\n",
      "        -0.01003727,  0.04401485]], dtype=float32)\n",
      " array([-0.14135575,  0.24103157, -0.02536675, -0.10606579,  0.05098346,\n",
      "        0.40988907, -0.03066774,  0.22140759, -0.54603946, -0.07381913],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(ar[0].shape)\n",
    "print(ar[0][0].shape)\n",
    "print(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01723874 -0.06937709  0.06620833 -0.01006251  0.01933407 -0.03479027\n",
      " -0.02931451 -0.0482297  -0.01208302  0.06472545]\n"
     ]
    }
   ],
   "source": [
    "print(ar[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
